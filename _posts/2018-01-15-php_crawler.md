--- 
layout: post
comments: true
title: 网络爬虫
date: 2018-01-15
tag: PHP
---


网页爬虫（又被称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定规则，自动地抓取万维网信息的程序或者脚本，另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。

![网络爬虫通用架构](/images/posts/common/crawler.png)


###  目录

* [产生背景](#background)
* [面临的问题](#problem)
* [分类](#category)


### <a name="background"></a>差生背景

随之网络的迅速发展，万维网成为大量信息的载体，如何有效地获取并利用这些信息成为一个巨大的挑战。搜索引擎（Search Engine），作为一个辅助人们检索信息的工具成为用户访问万维网的入口和指南。但是，这些通用型搜索引擎也存在着一定的局限性

* 不同领域、不同背景的用户往往具有不同的检索目的和需求，通用搜索引擎返回的结果包含大量用户不关心的内容

* 通用搜索引擎的目标去尽可能大的网络覆盖率，有限的搜索引擎资源与无限的网络数据资源之间的矛盾进一步加深

* 万维网数据形式的丰富和网络技术的不断发展，图片、数据库、音频、视频多媒体等不同数据大量出现，通用搜索引擎往往对这些信息含量密集切具有一定结构的数据无能为力，不能很好的发现和获取

* 通用搜索引擎大多提供基于关键字的检索，难以很好的发现和获取

为了解决上述问题，定向抓取相关网页资源的聚焦爬虫应运而生。聚焦爬虫是一个自动下载网页的程序，它根据既定的抓取目标，有选择的访问万维网上的网页与相关的链接，获取所需要的信息。与通用爬虫不同，聚焦爬虫并不追求大的覆盖，而将目标定位抓取某一特定主题内容相关的网页，为面向主题的用户查询准备数据资源。


####  聚焦爬虫工作原理以及关键技术概述

网络爬虫是一个自动提取网页的程序，它为搜索引擎从万维网上下载网页，是搜索亲戚的重要组成。传统爬虫从一个或若干个初始网页的URL开始，在抓取网页的过程中，不断从当前页面上抽取新的URL放入队列，知道满足系统的一定停止条件。聚焦爬虫的工作流程较为复杂，需要根据一定的网页分析算法过滤与主题无关的链接，保留有用的链接并将其放入等待抓取的URL队列。然后，它将根据一定的搜索策略从队列中选择下一步要抓取的网页URL，并重新上述过程，直到达到系统的某一条件时停止。另外，所有被爬虫抓取的网页将会被系统存储，进行一定的分析、过滤，并建立索引，以便之后的查询和检索。


###  <a name="problem"></a>面临的问题


Internet上网页的数据是庞大的，但是有很多页面和内容是重复的；动态页面的存在：客户端、服务器端脚本语言的应用使得指向相同web信息的URL数量呈指数及增长。上述特征使得网络爬虫面临一定的困难，主要体现在web信息的巨大容量使得爬虫在给定时间内只能下载少量页面。研究表明没有哪个搜索引擎能索引超出16%的internet上web页面，即使能够提取全部页面，也没有足够的空间来存储。


为来提高爬行效率，爬虫需要在单位时间内尽可能多的获取高质量页面，是它面临的难题之一。当前有五种表示页面质量高低的方式： Slimilarity(页面与爬虫主题的相似度)、 BackLink(页面在web图中的入度大小)、PageRank(指向它的所有页面平均权值之和)、ForwardLink(页面在web图中的出度大小)、Location(页面的信息位置)、Parallel(并行性问题)。 为了提高爬行速度，网络通常会采取并行爬行的工作方式，随之引入新的问题：重复性（并行运行的爬虫或爬行路线同时运行增加了重复页面）、质量问题（并行运行时，每个爬虫或爬行线程只能获取部分页面，导致页面质量下降）、通信宽带代价（并行运行时，每个爬虫或爬行线程之间不可避免的要进行一些通信）。并行运行时，网络爬虫通常采取三种方式：独立方式（各个爬虫独立爬行页面，互不通信）、动态分配释放（由一个中央协调器动态协调分配URL给各个爬虫）、静态分配方式（URL事先划分给各个爬虫）.


###  <a name="category"></a>分类


网络爬虫按照系统结构和实现技术，大致可以分为以下几种类型：通用网络爬虫、聚焦网络爬虫、增量式网络爬虫、深层网络爬虫


####  通用网络爬虫

通用网络爬虫又称全网爬虫，爬行对象从一些种子URL扩充到整个web， 主要为门户站点所搜引擎和大型web服务提供商采集数据。由于商业原因，它们的技术细节很少公布出来。这类网络爬虫的爬行范围和数量巨大，对于爬行速度和存储空间要求较高，对于爬行页面的顺序要求相对较低，同时由于待刷新的页面太多，通常采用并行工作方式，但需要较长时间才能刷新一次页面。虽然存在一定缺陷，通用网络爬虫适用于为搜索引擎搜索广泛的主题，有较强的应用价值。


通用网络爬虫的结构大致可以分为页面爬行模块、页面分析模块、链接过滤模块、页面数据库、URL队列、初始URL集合几个部分。为提供工作效率，通用网络爬虫会采取一定的爬行策略。常用的爬行策略有：深度优先策略、广度优先策略。

* 深度优先策略： 其基本方法是按照深度由低到高的顺序，依次访问下一级网络链接，直到不能在深入为止。爬虫在完成一个爬行分支后返回到上一链接节点进一步搜索其他链接。当所有链接遍历完后，爬行任务结束。这种策略比较适合垂直搜索或站内搜索，但爬行页面内容层次较深的站点时会造成资源的巨大浪费

* 广度优先策略：此策略按照网页内容目录层次深浅来爬行页面，处于较浅目录层次的页面首先被爬行。当同一层次中的页面爬行完毕后，爬虫再深入下一层继续爬行。这种策略能够有效控制页面的爬行深度，避免遇到一个无穷深层分支时无法结束爬行的问题，实现方便，无需存储大量中间节点，不足之处在于需要较长时间才能爬行到目录层次较深的页面


#### 聚焦网络爬虫 




###  每日一言

* 

<br>

转载请注明： [王龙的博客](http://www.wanglong.org.cn) >> [网络爬虫](http://www.wanglong.org.cn/2018/01/php_crawler/)